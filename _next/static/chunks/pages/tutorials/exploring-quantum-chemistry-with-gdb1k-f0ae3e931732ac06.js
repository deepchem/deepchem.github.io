(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[926],{8927:function(s,a,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/tutorials/exploring-quantum-chemistry-with-gdb1k",function(){return n(4288)}])},4288:function(s,a,n){"use strict";n.r(a),n.d(a,{default:function(){return d}});var p=n(5893),e=n(1618),l=n(6485),t={html:'<main>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <h1>\n      Exploring Quantum Chemistry with GDB1k\n      <a class="anchor-link" href="#Exploring-Quantum-Chemistry-with-GDB1k">\n       \xb6\n      </a>\n     </h1>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      Most of the tutorials we\'ve walked you through so far have focused on applications to the drug discovery realm, but DeepChem\'s tool suite works for molecular design problems generally. In this tutorial, we\'re going to walk through an example of how to train a simple molecular machine learning for the task of predicting the atomization energy of a molecule. (Remember that the atomization energy is the energy required to form 1 mol of gaseous atoms from 1 mol of the molecule in its standard state under standard conditions).\n     </p>\n     <h2>\n      Colab\n      <a class="anchor-link" href="#Colab">\n       \xb6\n      </a>\n     </h2>\n     <p>\n      This tutorial and the rest in this sequence can be done in Google colab. If you\'d like to open this notebook in colab, you can use the following link.\n     </p>\n     <p>\n      <a href="https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Exploring_Quantum_Chemistry_with_GDB1k.ipynb">\n       <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>\n      </a>\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[\xa0]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="o">!</span>pip install --pre deepchem\n<span class="kn">import</span> <span class="nn">deepchem</span>\n<span class="n">deepchem</span><span class="o">.</span><span class="n">__version__</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      With our setup in place, let\'s do a few standard imports to get the ball rolling.\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[1]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="kn">import</span> <span class="nn">deepchem</span> <span class="k">as</span> <span class="nn">dc</span>\n<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>\n<span class="kn">from</span> <span class="nn">sklearn.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidge</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      The ntext step we want to do is load our dataset. We\'re using a small dataset we\'ve prepared that\'s pulled out of the larger GDB benchmarks. The dataset contains the atomization energies for 1K small molecules.\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[2]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="n">tasks</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"atomization_energy"</span><span class="p">]</span>\n<span class="n">dataset_file</span> <span class="o">=</span> <span class="s2">"../../datasets/gdb1k.sdf"</span>\n<span class="n">smiles_field</span> <span class="o">=</span> <span class="s2">"smiles"</span>\n<span class="n">mol_field</span> <span class="o">=</span> <span class="s2">"mol"</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      We now need a way to transform molecules that is useful for prediction of atomization energy. This representation draws on foundational work [1] that represents a molecule\'s 3D electrostatic structure as a 2D matrix $C$ of distances scaled by charges, where the $ij$-th element is represented by the following charge structure.\n     </p>\n     <p>\n      $C_{ij} = \\frac{q_i q_j}{r_{ij}^2}$\n     </p>\n     <p>\n      If you\'re observing carefully, you might ask, wait doesn\'t this mean that molecules with different numbers of atoms generate matrices of different sizes? In practice the trick to get around this is that the matrices are "zero-padded." That is, if you\'re making coulomb matrices for a set of molecules, you pick a maximum number of atoms $N$, make the matrices $N\\times N$ and set to zero all the extra entries for this molecule. (There\'s a couple extra tricks that are done under the hood beyond this. Check out reference [1] or read the source code in DeepChem!)\n     </p>\n     <p>\n      DeepChem has a built in featurization class\n      <code>\n       dc.feat.CoulombMatrixEig\n      </code>\n      that can generate these featurizations for you.\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[3]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="n">featurizer</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">feat</span><span class="o">.</span><span class="n">CoulombMatrixEig</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="n">remove_hydrogens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      Note that in this case, we set the maximum number of atoms to $N = 23$. Let\'s now load our dataset file into DeepChem. As in the previous tutorials, we use a\n      <code>\n       Loader\n      </code>\n      class, in particular\n      <code>\n       dc.data.SDFLoader\n      </code>\n      to load our\n      <code>\n       .sdf\n      </code>\n      file into DeepChem. The following snippet shows how we do this:\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[4]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">SDFLoader</span><span class="p">(</span>\n      <span class="n">tasks</span><span class="o">=</span><span class="p">[</span><span class="s2">"atomization_energy"</span><span class="p">],</span>\n      <span class="n">featurizer</span><span class="o">=</span><span class="n">featurizer</span><span class="p">)</span>\n<span class="n">dataset</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">dataset_file</span><span class="p">)</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n  <div class="jp-Cell-outputWrapper">\n   <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n   </div>\n   <div class="jp-OutputArea jp-Cell-outputArea">\n    <div class="jp-OutputArea-child">\n     <div class="jp-OutputPrompt jp-OutputArea-prompt">\n     </div>\n     <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">\n      <pre class="overflow-x-scroll font-mono">RDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\nRDKit WARNING: [17:25:11] Warning: molecule is tagged as 3D, but all Z coords are zero\n/Users/peastman/workspace/deepchem/deepchem/feat/molecule_featurizers/coulomb_matrices.py:141: RuntimeWarning: divide by zero encountered in true_divide\n  m = np.outer(z, z) / d\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      For the purposes of this tutorial, we\'re going to do a random split of the dataset into training, validation, and test. In general, this split is weak and will considerably overestimate the accuracy of our models, but for now in this simple tutorial isn\'t a bad place to get started.\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[5]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="n">random_splitter</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">splits</span><span class="o">.</span><span class="n">RandomSplitter</span><span class="p">()</span>\n<span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">random_splitter</span><span class="o">.</span><span class="n">train_valid_test_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      One issue that Coulomb matrix featurizations have is that the range of entries in the matrix $C$ can be large. The charge $q_1q_2/r^2$ term can range very widely. In general, a wide range of values for inputs can throw off learning for the neural network. For this, a common fix is to normalize the input values so that they fall into a more standard range. Recall that the normalization transform applies to each feature $X_i$ of datapoint $X$\n     </p>\n     <p>\n      $\\hat{X_i} = \\frac{X_i - \\mu_i}{\\sigma_i}$\n     </p>\n     <p>\n      where $\\mu_i$ and $\\sigma_i$ are the mean and standard deviation of the $i$-th feature. This transformation enables the learning to proceed smoothly. A second point is that the atomization energies also fall across a wide range. So we apply an analogous transformation normalization transformation to the output to scale the energies better. We use DeepChem\'s transformation API to make this happen:\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[6]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="n">transformers</span> <span class="o">=</span> <span class="p">[</span>\n    <span class="n">dc</span><span class="o">.</span><span class="n">trans</span><span class="o">.</span><span class="n">NormalizationTransformer</span><span class="p">(</span><span class="n">transform_X</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">),</span>\n    <span class="n">dc</span><span class="o">.</span><span class="n">trans</span><span class="o">.</span><span class="n">NormalizationTransformer</span><span class="p">(</span><span class="n">transform_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">)]</span>\n\n<span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">[</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">test_dataset</span><span class="p">]:</span>\n  <span class="k">for</span> <span class="n">transformer</span> <span class="ow">in</span> <span class="n">transformers</span><span class="p">:</span>\n      <span class="n">dataset</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      Now that we have the data cleanly transformed, let\'s do some simple machine learning. We\'ll start by constructing a random forest on top of the data. We\'ll use DeepChem\'s hyperparameter tuning module to do this.\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[7]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="k">def</span> <span class="nf">rf_model_builder</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="o">**</span><span class="n">model_params</span><span class="p">):</span>\n  <span class="n">sklearn_model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">model_params</span><span class="p">)</span>\n  <span class="k">return</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SklearnModel</span><span class="p">(</span><span class="n">sklearn_model</span><span class="p">,</span> <span class="n">model_dir</span><span class="p">)</span>\n<span class="n">params_dict</span> <span class="o">=</span> <span class="p">{</span>\n    <span class="s2">"n_estimators"</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>\n    <span class="s2">"max_features"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"auto"</span><span class="p">,</span> <span class="s2">"sqrt"</span><span class="p">,</span> <span class="s2">"log2"</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>\n<span class="p">}</span>\n\n<span class="n">metric</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">)</span>\n<span class="n">optimizer</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">hyper</span><span class="o">.</span><span class="n">GridHyperparamOpt</span><span class="p">(</span><span class="n">rf_model_builder</span><span class="p">)</span>\n<span class="n">best_rf</span><span class="p">,</span> <span class="n">best_rf_hyperparams</span><span class="p">,</span> <span class="n">all_rf_results</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">hyperparam_search</span><span class="p">(</span>\n    <span class="n">params_dict</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">output_transformers</span><span class="o">=</span><span class="n">transformers</span><span class="p">,</span>\n    <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">use_max</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>\n<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">all_rf_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>\n    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">\'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>\n<span class="nb">print</span><span class="p">(</span><span class="s1">\'Best hyperparams:\'</span><span class="p">,</span> <span class="n">best_rf_hyperparams</span><span class="p">)</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n  <div class="jp-Cell-outputWrapper">\n   <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n   </div>\n   <div class="jp-OutputArea jp-Cell-outputArea">\n    <div class="jp-OutputArea-child">\n     <div class="jp-OutputPrompt jp-OutputArea-prompt">\n     </div>\n     <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">\n      <pre class="overflow-x-scroll font-mono">_max_featuresauto_n_estimators_10: 91166.92046422893\n_max_featuressqrt_n_estimators_10: 90145.02789928475\n_max_featureslog2_n_estimators_10: 85589.77206099383\n_max_featuresNone_n_estimators_10: 86870.06019336461\n_max_featuresauto_n_estimators_100: 86385.9006447343\n_max_featuressqrt_n_estimators_100: 85051.76415912053\n_max_featureslog2_n_estimators_100: 86443.79468510246\n_max_featuresNone_n_estimators_100: 85464.79840440316\nBest hyperparams: (100, \'sqrt\')\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <p>\n      Let\'s build one more model, a kernel ridge regression, on top of this raw data.\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n     In\xa0[8]:\n    </div>\n    <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n     <div class="cm-editor cm-s-jupyter">\n      <div class="highlight hl-ipython3">\n       <pre class="overflow-x-scroll font-mono"><span></span><span class="k">def</span> <span class="nf">krr_model_builder</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="o">**</span><span class="n">model_params</span><span class="p">):</span>\n  <span class="n">sklearn_model</span> <span class="o">=</span> <span class="n">KernelRidge</span><span class="p">(</span><span class="o">**</span><span class="n">model_params</span><span class="p">)</span>\n  <span class="k">return</span> <span class="n">dc</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SklearnModel</span><span class="p">(</span><span class="n">sklearn_model</span><span class="p">,</span> <span class="n">model_dir</span><span class="p">)</span>\n\n<span class="n">params_dict</span> <span class="o">=</span> <span class="p">{</span>\n    <span class="s2">"kernel"</span><span class="p">:</span> <span class="p">[</span><span class="s2">"laplacian"</span><span class="p">],</span>\n    <span class="s2">"alpha"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">],</span>\n    <span class="s2">"gamma"</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0001</span><span class="p">]</span>\n<span class="p">}</span>\n\n<span class="n">metric</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">(</span><span class="n">dc</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span><span class="p">)</span>\n<span class="n">optimizer</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">hyper</span><span class="o">.</span><span class="n">GridHyperparamOpt</span><span class="p">(</span><span class="n">krr_model_builder</span><span class="p">)</span>\n<span class="n">best_krr</span><span class="p">,</span> <span class="n">best_krr_hyperparams</span><span class="p">,</span> <span class="n">all_krr_results</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">hyperparam_search</span><span class="p">(</span>\n    <span class="n">params_dict</span><span class="p">,</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="n">valid_dataset</span><span class="p">,</span> <span class="n">output_transformers</span><span class="o">=</span><span class="n">transformers</span><span class="p">,</span>\n    <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span> <span class="n">use_max</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>\n<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">all_krr_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>\n    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">\'</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s1">\'</span><span class="p">)</span>\n<span class="nb">print</span><span class="p">(</span><span class="s1">\'Best hyperparams:\'</span><span class="p">,</span> <span class="n">best_krr_hyperparams</span><span class="p">)</span>\n</pre>\n      </div>\n     </div>\n    </div>\n   </div>\n  </div>\n  <div class="jp-Cell-outputWrapper">\n   <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n   </div>\n   <div class="jp-OutputArea jp-Cell-outputArea">\n    <div class="jp-OutputArea-child">\n     <div class="jp-OutputPrompt jp-OutputArea-prompt">\n     </div>\n     <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">\n      <pre class="overflow-x-scroll font-mono">_alpha_0.000100_gamma_0.000100_kernellaplacian: 94056.64820129865\nBest hyperparams: (\'laplacian\', 0.0001, 0.0001)\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n  <div class="jp-Cell-inputWrapper" tabindex="0">\n   <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n   </div>\n   <div class="jp-InputArea jp-Cell-inputArea">\n    <div class="jp-InputPrompt jp-InputArea-prompt">\n    </div>\n    <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n     <h1>\n      Congratulations! Time to join the Community!\n      <a class="anchor-link" href="#Congratulations!-Time-to-join-the-Community!">\n       \xb6\n      </a>\n     </h1>\n     <p>\n      Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n     </p>\n     <h2>\n      Star DeepChem on\n      <a href="https://github.com/deepchem/deepchem">\n       GitHub\n      </a>\n      <a class="anchor-link" href="#Star-DeepChem-on-GitHub">\n       \xb6\n      </a>\n     </h2>\n     <p>\n      This helps build awareness of the DeepChem project and the tools for open source drug discovery that we\'re trying to build.\n     </p>\n     <h2>\n      Join the DeepChem Gitter\n      <a class="anchor-link" href="#Join-the-DeepChem-Gitter">\n       \xb6\n      </a>\n     </h2>\n     <p>\n      The DeepChem\n      <a href="https://gitter.im/deepchem/Lobby">\n       Gitter\n      </a>\n      hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!\n     </p>\n     <h1>\n      Bibliography:\n      <a class="anchor-link" href="#Bibliography:">\n       \xb6\n      </a>\n     </h1>\n     <p>\n      [1]\n      <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.98.146401">\n       https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.98.146401\n      </a>\n     </p>\n    </div>\n   </div>\n  </div>\n </div>\n</main>\n'},o=n(7294),r=n(7466),i=n.n(r);let c=()=>((0,o.useEffect)(()=>{var s,a;null===(s=document.getElementsByClassName("scroll-nav")[0])||void 0===s||s.remove();let n=document.querySelector(".notebook"),p=document.querySelector(".notebook");p&&n&&i().init(n,{sections:"h1, h2",insertTarget:p,insertLocation:"after"}),null==MathJax||null===(a=MathJax.Hub)||void 0===a||a.Queue(["Typeset",MathJax.Hub])},[]),(0,p.jsx)("div",{className:"overflow-x-scroll",dangerouslySetInnerHTML:{__html:"".concat(t.html," ").concat(l.Z)}}));c.Layout=e.Z;var d=c}},function(s){s.O(0,[2443,9774,2888,179],function(){return s(s.s=8927)}),_N_E=s.O()}]);