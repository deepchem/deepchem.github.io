(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[2373],{6712:function(e,r,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/tutorials/introduction-to-grover",function(){return n(6359)}])},6359:function(e,r,n){"use strict";n.r(r),n.d(r,{default:function(){return c}});var a=n(5893),o=n(1618),t=n(6485),s={html:'<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h1>\n     Introduction to GROVER\n     <a class="anchor-link" href="#Introduction-to-GROVER">\n      \xb6\n     </a>\n    </h1>\n    <p>\n     In this tutorial, we will go over what Grover is, and how to get it up and running.\n    </p>\n    <p>\n     GROVER, or, Graph Representation frOm selfsuperVised mEssage passing tRansformer, is a novel framework proposed by Tencent AI Lab. GROVER utilizes self-supervised tasks in the node, edge and graph level in order to learn rich structural and semantic information of molecules from large unlabelled molecular datasets. GROVER integrates Message Passing Networks into a Transformer-style architecture to deliver more expressive molecular encoding.\n    </p>\n    <p>\n     Reference Paper:\n     <a href="https://drug.ai.tencent.com/publications/GROVER.pdf">\n      Rong, Yu, et al. "Grover: Self-supervised message passing transformer on large-scale molecular data." Advances in Neural Information Processing Systems (2020).\n     </a>\n    </p>\n    <h2>\n     Colab\n     <a class="anchor-link" href="#Colab">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     This tutorial and the rest in this sequence are designed to be done in Google colab. If you\'d like to open this notebook in colab, you can use the following link.\n    </p>\n    <p>\n     <a href="https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Introduction_to_GROVER.ipynb">\n      <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>\n     </a>\n    </p>\n    <h2>\n     Setup\n     <a class="anchor-link" href="#Setup">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     To run DeepChem within Colab, you\'ll need to run the following installation commands. This will take about 5 minutes to run to completion and install your environment. You can of course run this tutorial locally if you prefer. In that case, don\'t run these cells since they will download and install Anaconda on your local machine.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Import and Setup required modules.\n     <a class="anchor-link" href="#Import-and-Setup-required-modules.">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     We will first clone the repository onto the preferred platform, then install it as a library. We will also import deepchem and install descriptastorus.\n    </p>\n    <p>\n     NOTE: The\n     <a href="https://github.com/tencent-ailab/grover">\n      original GROVER repository\n     </a>\n     does not contain a\n     <code>\n      setup.py\n     </code>\n     file, thus we are currently using a fork which does.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[1]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># Clone the forked repository.</span>\n<span class="o">%</span><span class="n">cd</span> <span class="n">drive</span><span class="o">/</span><span class="n">MyDrive</span>\n<span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">atreyamaj</span><span class="o">/</span><span class="n">grover</span><span class="o">.</span><span class="n">git</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">/content/drive/MyDrive\nfatal: destination path \'grover\' already exists and is not an empty directory.\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[2]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># Navigate to the working folder.</span>\n<span class="o">%</span><span class="n">cd</span> <span class="n">grover</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">/content/drive/MyDrive/grover\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[3]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># Install the forked repository.</span>\n<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">./</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">Obtaining file:///content/drive/MyDrive/grover\nInstalling collected packages: grover\n  Running setup.py develop for grover\nSuccessfully installed grover-1.0.0\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[4]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># Install deepchem and descriptastorus.</span>\n<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">deepchem</span>\n<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">bp</span><span class="o">-</span><span class="n">kelley</span><span class="o">/</span><span class="n">descriptastorus</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">Collecting deepchem\n  Downloading deepchem-2.6.1-py3-none-any.whl (608 kB)\n     |████████████████████████████████| 608 kB 28.3 MB/s \nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.2)\nRequirement already satisfied: numpy&gt;=1.21 in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.21.6)\nCollecting rdkit-pypi\n  Downloading rdkit_pypi-2022.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n     |████████████████████████████████| 22.5 MB 1.4 MB/s \nRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.3.5)\nRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.0)\nRequirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;deepchem) (2022.1)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;deepchem) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;deepchem) (1.15.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi-&gt;deepchem) (7.1.2)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;deepchem) (3.1.0)\nInstalling collected packages: rdkit-pypi, deepchem\nSuccessfully installed deepchem-2.6.1 rdkit-pypi-2022.3.1\nCollecting git+https://github.com/bp-kelley/descriptastorus\n  Cloning https://github.com/bp-kelley/descriptastorus to /tmp/pip-req-build-_462lldf\n  Running command git clone -q https://github.com/bp-kelley/descriptastorus /tmp/pip-req-build-_462lldf\nCollecting pandas_flavor\n  Downloading pandas_flavor-0.3.0-py3-none-any.whl (6.3 kB)\nRequirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from pandas_flavor-&gt;descriptastorus==2.3.0.6) (0.18.2)\n  Downloading pandas_flavor-0.2.0-py2.py3-none-any.whl (6.6 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandas_flavor-&gt;descriptastorus==2.3.0.6) (1.3.5)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;pandas_flavor-&gt;descriptastorus==2.3.0.6) (2.8.2)\nRequirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;pandas_flavor-&gt;descriptastorus==2.3.0.6) (2022.1)\nRequirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;pandas_flavor-&gt;descriptastorus==2.3.0.6) (1.21.6)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;pandas_flavor-&gt;descriptastorus==2.3.0.6) (1.15.0)\nRequirement already satisfied: setuptools&gt;=40.4 in /usr/local/lib/python3.7/dist-packages (from xarray-&gt;pandas_flavor-&gt;descriptastorus==2.3.0.6) (57.4.0)\nBuilding wheels for collected packages: descriptastorus\n  Building wheel for descriptastorus (setup.py) ... done\n  Created wheel for descriptastorus: filename=descriptastorus-2.3.0.6-py3-none-any.whl size=60704 sha256=10872f9972ee502829c712449b7dbd8d54717461dce2fdffe495f21e10044446\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k9kvyu6l/wheels/f9/c3/4f/e7d01f4f2f1a89aef8f0ef088beb4a94976324f3ee21410b10\nSuccessfully built descriptastorus\nInstalling collected packages: pandas-flavor, descriptastorus\nSuccessfully installed descriptastorus-2.3.0.6 pandas-flavor-0.2.0\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Extracting semantic motif labels\n     <a class="anchor-link" href="#Extracting-semantic-motif-labels">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     The semantic motif label is extracted by\n     <code>\n      scripts/save_feature.py\n     </code>\n     with feature generator\n     <code>\n      fgtasklabel\n     </code>\n     .\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[5]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">save_features</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span><span class="o">.</span><span class="n">csv</span>  \\\n                                <span class="o">--</span><span class="n">save_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span><span class="o">.</span><span class="n">npz</span>   \\\n                                <span class="o">--</span><span class="n">features_generator</span> <span class="n">fgtasklabel</span> \\\n                                <span class="o">--</span><span class="n">restart</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\n100% 5970/5970 [00:09&lt;00:00, 620.91it/s]\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Extracting atom/bond contextual properties (vocabulary)\n     <a class="anchor-link" href="#Extracting-atom/bond-contextual-properties-(vocabulary)">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     The atom/bond Contextual Property (Vocabulary) is extracted by\n     <code>\n      scripts/build_vocab.py\n     </code>\n     .\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[6]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">build_vocab</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span><span class="o">.</span><span class="n">csv</span>  \\\n                             <span class="o">--</span><span class="n">vocab_save_folder</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span>  \\\n                             <span class="o">--</span><span class="n">dataset_name</span> <span class="n">tryout</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\nBuilding atom vocab from file: exampledata/pretrain/tryout.csv\n50000it [00:04, 10946.14it/s]\natom vocab size 324\nBuilding bond vocab from file: exampledata/pretrain/tryout.csv\n50000it [00:16, 3094.21it/s]\nbond vocab size 353\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Splitting the data\n     <a class="anchor-link" href="#Splitting-the-data">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     To accelerate the data loading and reduce the memory cost in the multi-gpu pretraining scenario, the unlabelled molecular data need to be spilt into several parts using\n     <code>\n      scripts/split_data.py\n     </code>\n     .\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[7]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">split_data</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span><span class="o">.</span><span class="n">csv</span>  \\\n                             <span class="o">--</span><span class="n">features_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span><span class="o">.</span><span class="n">npz</span>  \\\n                             <span class="o">--</span><span class="n">sample_per_file</span> <span class="mi">100</span>  \\\n                             <span class="o">--</span><span class="n">output_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\nNumber of files: 60\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Running Pretraining on Single GPU\n     <a class="anchor-link" href="#Running-Pretraining-on-Single-GPU">\n      \xb6\n     </a>\n    </h2>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[8]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="n">pretrain</span> \\\n               <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout</span> \\\n               <span class="o">--</span><span class="n">save_dir</span> <span class="n">model</span><span class="o">/</span><span class="n">tryout</span> \\\n               <span class="o">--</span><span class="n">atom_vocab_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout_atom_vocab</span><span class="o">.</span><span class="n">pkl</span> \\\n               <span class="o">--</span><span class="n">bond_vocab_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">pretrain</span><span class="o">/</span><span class="n">tryout_bond_vocab</span><span class="o">.</span><span class="n">pkl</span> \\\n               <span class="o">--</span><span class="n">batch_size</span> <span class="mi">32</span> \\\n               <span class="o">--</span><span class="n">dropout</span> <span class="mf">0.1</span> \\\n               <span class="o">--</span><span class="n">depth</span> <span class="mi">5</span> \\\n               <span class="o">--</span><span class="n">num_attn_head</span> <span class="mi">1</span> \\\n               <span class="o">--</span><span class="n">hidden_size</span> <span class="mi">100</span> \\\n               <span class="o">--</span><span class="n">epochs</span> <span class="mi">3</span> \\\n               <span class="o">--</span><span class="n">init_lr</span> <span class="mf">0.0002</span> \\\n               <span class="o">--</span><span class="n">max_lr</span> <span class="mf">0.0004</span> \\\n               <span class="o">--</span><span class="n">final_lr</span> <span class="mf">0.0001</span> \\\n               <span class="o">--</span><span class="n">weight_decay</span> <span class="mf">0.0000001</span> \\\n               <span class="o">--</span><span class="n">activation</span> <span class="n">PReLU</span> \\\n               <span class="o">--</span><span class="n">backbone</span> <span class="n">gtrans</span> \\\n               <span class="o">--</span><span class="n">embedding_output_type</span> <span class="n">both</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\n[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\nNamespace(activation=\'PReLU\', atom_vocab_path=\'exampledata/pretrain/tryout_atom_vocab.pkl\', backbone=\'gtrans\', batch_size=32, bias=False, bond_drop_rate=0, bond_vocab_path=\'exampledata/pretrain/tryout_bond_vocab.pkl\', cuda=True, data_path=\'exampledata/pretrain/tryout\', dense=False, depth=5, dist_coff=0.1, dropout=0.1, embedding_output_type=\'both\', enable_multi_gpu=False, epochs=3, fg_label_path=None, final_lr=0.0001, fine_tune_coff=1, hidden_size=100, init_lr=0.0002, max_lr=0.0004, no_cache=True, num_attn_head=1, num_mt_block=1, parser_name=\'pretrain\', save_dir=\'model/tryout\', save_interval=9999999999, undirected=False, warmup_epochs=2.0, weight_decay=1e-07)\nLoading data\nLoading data:\nNumber of files: 60\nNumber of samples: 5970\nSamples/file: 100\nSplitting data with seed 0.\nTotal size = 5,970 | train size = 5,400 | val size = 570\natom vocab size: 324, bond vocab size: 353, Number of FG tasks: 85\nPre-loaded test data: 6\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nRestore checkpoint, current epoch: 2\nGROVEREmbedding(\n  (encoders): GTransEncoder(\n    (edge_blocks): ModuleList(\n      (0): MTBlock(\n        (heads): ModuleList(\n          (0): Head(\n            (mpn_q): MPNEncoder(\n              (dropout_layer): Dropout(p=0.1, inplace=False)\n              (act_func): PReLU(num_parameters=1)\n              (W_h): Linear(in_features=100, out_features=100, bias=False)\n            )\n            (mpn_k): MPNEncoder(\n              (dropout_layer): Dropout(p=0.1, inplace=False)\n              (act_func): PReLU(num_parameters=1)\n              (W_h): Linear(in_features=100, out_features=100, bias=False)\n            )\n            (mpn_v): MPNEncoder(\n              (dropout_layer): Dropout(p=0.1, inplace=False)\n              (act_func): PReLU(num_parameters=1)\n              (W_h): Linear(in_features=100, out_features=100, bias=False)\n            )\n          )\n        )\n        (act_func): PReLU(num_parameters=1)\n        (dropout_layer): Dropout(p=0.1, inplace=False)\n        (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (W_i): Linear(in_features=165, out_features=100, bias=False)\n        (attn): MultiHeadedAttention(\n          (linear_layers): ModuleList(\n            (0): Linear(in_features=100, out_features=100, bias=True)\n            (1): Linear(in_features=100, out_features=100, bias=True)\n            (2): Linear(in_features=100, out_features=100, bias=True)\n          )\n          (output_linear): Linear(in_features=100, out_features=100, bias=False)\n          (attention): Attention()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (W_o): Linear(in_features=100, out_features=100, bias=False)\n        (sublayer): SublayerConnection(\n          (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (node_blocks): ModuleList(\n      (0): MTBlock(\n        (heads): ModuleList(\n          (0): Head(\n            (mpn_q): MPNEncoder(\n              (dropout_layer): Dropout(p=0.1, inplace=False)\n              (act_func): PReLU(num_parameters=1)\n              (W_h): Linear(in_features=100, out_features=100, bias=False)\n            )\n            (mpn_k): MPNEncoder(\n              (dropout_layer): Dropout(p=0.1, inplace=False)\n              (act_func): PReLU(num_parameters=1)\n              (W_h): Linear(in_features=100, out_features=100, bias=False)\n            )\n            (mpn_v): MPNEncoder(\n              (dropout_layer): Dropout(p=0.1, inplace=False)\n              (act_func): PReLU(num_parameters=1)\n              (W_h): Linear(in_features=100, out_features=100, bias=False)\n            )\n          )\n        )\n        (act_func): PReLU(num_parameters=1)\n        (dropout_layer): Dropout(p=0.1, inplace=False)\n        (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (W_i): Linear(in_features=151, out_features=100, bias=False)\n        (attn): MultiHeadedAttention(\n          (linear_layers): ModuleList(\n            (0): Linear(in_features=100, out_features=100, bias=True)\n            (1): Linear(in_features=100, out_features=100, bias=True)\n            (2): Linear(in_features=100, out_features=100, bias=True)\n          )\n          (output_linear): Linear(in_features=100, out_features=100, bias=False)\n          (attention): Attention()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (W_o): Linear(in_features=100, out_features=100, bias=False)\n        (sublayer): SublayerConnection(\n          (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ffn_atom_from_atom): PositionwiseFeedForward(\n      (W_1): Linear(in_features=251, out_features=400, bias=True)\n      (W_2): Linear(in_features=400, out_features=100, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (act_func): PReLU(num_parameters=1)\n    )\n    (ffn_atom_from_bond): PositionwiseFeedForward(\n      (W_1): Linear(in_features=251, out_features=400, bias=True)\n      (W_2): Linear(in_features=400, out_features=100, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (act_func): PReLU(num_parameters=1)\n    )\n    (ffn_bond_from_atom): PositionwiseFeedForward(\n      (W_1): Linear(in_features=265, out_features=400, bias=True)\n      (W_2): Linear(in_features=400, out_features=100, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (act_func): PReLU(num_parameters=1)\n    )\n    (ffn_bond_from_bond): PositionwiseFeedForward(\n      (W_1): Linear(in_features=265, out_features=400, bias=True)\n      (W_2): Linear(in_features=400, out_features=100, bias=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (act_func): PReLU(num_parameters=1)\n    )\n    (atom_from_atom_sublayer): SublayerConnection(\n      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (atom_from_bond_sublayer): SublayerConnection(\n      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (bond_from_atom_sublayer): SublayerConnection(\n      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (bond_from_bond_sublayer): SublayerConnection(\n      (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (act_func_node): PReLU(num_parameters=1)\n    (act_func_edge): PReLU(num_parameters=1)\n    (dropout_layer): Dropout(p=0.1, inplace=False)\n  )\n)\nTotal parameters: 768614\nEP:3 Model Saved on: model/tryout/model.ep3\nTotal Time: 14.828\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h1>\n     Training and Finetuning\n     <a class="anchor-link" href="#Training-and-Finetuning">\n      \xb6\n     </a>\n    </h1>\n    <h2>\n     Extracting Molecular Features\n     <a class="anchor-link" href="#Extracting-Molecular-Features">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     Given a labelled molecular dataset, it is possible to extract the additional molecular features in order to train &amp; finetune the model from the existing pretrained model. The feature matrix is stored as\n     <code>\n      .npz\n     </code>\n     .\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[9]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">save_features</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">csv</span> \\\n                                <span class="o">--</span><span class="n">save_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">npz</span> \\\n                                <span class="o">--</span><span class="n">features_generator</span> <span class="n">rdkit_2d_normalized</span> \\\n                                <span class="o">--</span><span class="n">restart</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n[21:04:21] WARNING: not removing hydrogen atom without neighbors\n  0% 6/2039 [00:01&lt;06:41,  5.07it/s][21:04:23] WARNING: not removing hydrogen atom without neighbors\n  3% 53/2039 [00:02&lt;00:56, 35.31it/s][21:04:24] WARNING: not removing hydrogen atom without neighbors\n  5% 95/2039 [00:04&lt;01:22, 23.62it/s][21:04:26] WARNING: not removing hydrogen atom without neighbors\n  6% 115/2039 [00:04&lt;00:50, 38.29it/s][21:04:27] WARNING: not removing hydrogen atom without neighbors\n  7% 152/2039 [00:06&lt;01:23, 22.62it/s][21:04:28] WARNING: not removing hydrogen atom without neighbors\n  8% 169/2039 [00:07&lt;01:46, 17.53it/s][21:04:29] WARNING: not removing hydrogen atom without neighbors\n[21:04:29] WARNING: not removing hydrogen atom without neighbors\n 10% 198/2039 [00:08&lt;01:02, 29.58it/s][21:04:30] WARNING: not removing hydrogen atom without neighbors\n 13% 268/2039 [00:11&lt;01:06, 26.67it/s][21:04:33] WARNING: not removing hydrogen atom without neighbors\n[21:04:33] WARNING: not removing hydrogen atom without neighbors\n[21:04:33] WARNING: not removing hydrogen atom without neighbors\n 15% 306/2039 [00:12&lt;01:08, 25.31it/s][21:04:34] WARNING: not removing hydrogen atom without neighbors\n[21:04:34] WARNING: not removing hydrogen atom without neighbors\n[21:04:34] WARNING: not removing hydrogen atom without neighbors\n 18% 372/2039 [00:16&lt;03:04,  9.03it/s][21:04:38] WARNING: not removing hydrogen atom without neighbors\n 21% 424/2039 [00:16&lt;00:46, 34.78it/s][21:04:39] WARNING: not removing hydrogen atom without neighbors\n[21:04:39] WARNING: not removing hydrogen atom without neighbors\n 23% 471/2039 [00:18&lt;00:51, 30.55it/s][21:04:40] WARNING: not removing hydrogen atom without neighbors\n 26% 528/2039 [00:20&lt;00:56, 26.79it/s][21:04:42] WARNING: not removing hydrogen atom without neighbors\n 27% 556/2039 [00:21&lt;00:58, 25.56it/s]WARNING: not removing hydrogen atom without neighbors\n 28% 571/2039 [00:22&lt;01:09, 21.01it/s][21:04:44] WARNING: not removing hydrogen atom without neighbors\n 29% 598/2039 [00:23&lt;01:02, 23.22it/s][21:04:45] WARNING: not removing hydrogen atom without neighbors\n 30% 619/2039 [00:24&lt;00:50, 28.33it/s][21:04:45] WARNING: not removing hydrogen atom without neighbors\n[21:04:45] WARNING: not removing hydrogen atom without neighbors\n 32% 645/2039 [00:25&lt;00:52, 26.57it/s][21:04:47] WARNING: not removing hydrogen atom without neighbors\n[21:04:47] WARNING: not removing hydrogen atom without neighbors\n 34% 689/2039 [00:27&lt;00:53, 25.23it/s][21:04:48] WARNING: not removing hydrogen atom without neighbors\n 35% 713/2039 [00:28&lt;01:02, 21.14it/s][21:04:50] WARNING: not removing hydrogen atom without neighbors\n 39% 800/2039 [00:32&lt;02:30,  8.23it/s]WARNING: not removing hydrogen atom without neighbors\n 40% 813/2039 [00:33&lt;01:26, 14.10it/s][21:04:55] WARNING: not removing hydrogen atom without neighbors\n 44% 901/2039 [00:36&lt;00:45, 24.82it/s][21:04:58] WARNING: not removing hydrogen atom without neighbors\n 44% 905/2039 [00:36&lt;00:46, 24.15it/s][21:04:58] WARNING: not removing hydrogen atom without neighbors\n 45% 908/2039 [00:37&lt;01:08, 16.55it/s][21:04:59] WARNING: not removing hydrogen atom without neighbors\n[21:04:59] WARNING: not removing hydrogen atom without neighbors\n[21:04:59] WARNING: not removing hydrogen atom without neighbors\n[21:05:00] WARNING: not removing hydrogen atom without neighbors\n 50% 1010/2039 [00:40&lt;00:30, 33.63it/s][21:05:02] WARNING: not removing hydrogen atom without neighbors\n 51% 1039/2039 [00:41&lt;00:34, 28.94it/s][21:05:03] WARNING: not removing hydrogen atom without neighbors\n 56% 1134/2039 [00:45&lt;00:33, 26.85it/s][21:05:07] WARNING: not removing hydrogen atom without neighbors\n 56% 1150/2039 [00:46&lt;00:37, 23.89it/s][21:05:07] WARNING: not removing hydrogen atom without neighbors\n 57% 1161/2039 [00:46&lt;00:29, 29.93it/s][21:05:08] WARNING: not removing hydrogen atom without neighbors\n 57% 1168/2039 [00:46&lt;00:35, 24.50it/s]WARNING: not removing hydrogen atom without neighbors\n 58% 1186/2039 [00:47&lt;00:24, 34.22it/s][21:05:09] WARNING: not removing hydrogen atom without neighbors\n 58% 1192/2039 [00:47&lt;00:21, 39.24it/s][21:05:09] WARNING: not removing hydrogen atom without neighbors\n 61% 1235/2039 [00:49&lt;00:34, 23.35it/s][21:05:11] WARNING: not removing hydrogen atom without neighbors\n 62% 1264/2039 [00:50&lt;00:32, 23.94it/s][21:05:12] WARNING: not removing hydrogen atom without neighbors\n 62% 1268/2039 [00:50&lt;00:29, 25.95it/s][21:05:12] WARNING: not removing hydrogen atom without neighbors\n 62% 1273/2039 [00:50&lt;00:25, 29.91it/s][21:05:12] WARNING: not removing hydrogen atom without neighbors\n 63% 1289/2039 [00:51&lt;00:35, 21.19it/s][21:05:13] WARNING: not removing hydrogen atom without neighbors\n 63% 1294/2039 [00:51&lt;00:30, 24.51it/s][21:05:13] WARNING: not removing hydrogen atom without neighbors\n 64% 1297/2039 [00:51&lt;00:30, 24.42it/s][21:05:13] WARNING: not removing hydrogen atom without neighbors\n 64% 1308/2039 [00:52&lt;00:29, 24.50it/s]\n 65% 1318/2039 [00:52&lt;00:31, 23.25it/s][21:05:14] WARNING: not removing hydrogen atom without neighbors\n 66% 1339/2039 [00:53&lt;00:19, 35.84it/s][21:05:14] WARNING: not removing hydrogen atom without neighbors\n 66% 1354/2039 [00:53&lt;00:27, 25.00it/s][21:05:15] WARNING: not removing hydrogen atom without neighbors\n 68% 1384/2039 [00:55&lt;00:30, 21.15it/s][21:05:16] WARNING: not removing hydrogen atom without neighbors\n 71% 1443/2039 [00:57&lt;00:26, 22.41it/s][21:05:18] WARNING: not removing hydrogen atom without neighbors\n 71% 1451/2039 [00:57&lt;00:22, 26.27it/s][21:05:19] WARNING: not removing hydrogen atom without neighbors\n 72% 1467/2039 [00:58&lt;00:29, 19.33it/s][21:05:20] WARNING: not removing hydrogen atom without neighbors\n 72% 1471/2039 [00:58&lt;00:26, 21.24it/s][21:05:20] WARNING: not removing hydrogen atom without neighbors\n 77% 1568/2039 [01:02&lt;00:20, 23.17it/s][21:05:23] WARNING: not removing hydrogen atom without neighbors\n 78% 1591/2039 [01:02&lt;00:20, 22.13it/s][21:05:24] WARNING: not removing hydrogen atom without neighbors[21:05:24] \nWARNING: not removing hydrogen atom without neighbors\n[21:05:24] WARNING: not removing hydrogen atom without neighbors\n 79% 1616/2039 [01:03&lt;00:15, 26.82it/s][21:05:25] WARNING: not removing hydrogen atom without neighbors\n 79% 1620/2039 [01:04&lt;00:19, 21.82it/s][21:05:25] WARNING: not removing hydrogen atom without neighbors\n 82% 1665/2039 [01:05&lt;00:11, 31.94it/s][21:05:27] WARNING: not removing hydrogen atom without neighbors\n 82% 1671/2039 [01:05&lt;00:12, 29.68it/s][21:05:27] WARNING: not removing hydrogen atom without neighbors\n 83% 1685/2039 [01:06&lt;00:17, 19.79it/s][21:05:28] WARNING: not removing hydrogen atom without neighbors\n[21:05:28] WARNING: not removing hydrogen atom without neighbors\n 83% 1689/2039 [01:06&lt;00:17, 20.30it/s][21:05:28] WARNING: not removing hydrogen atom without neighbors\n 84% 1713/2039 [01:07&lt;00:14, 22.54it/s][21:05:29] WARNING: not removing hydrogen atom without neighbors\n 85% 1731/2039 [01:08&lt;00:12, 25.18it/s][21:05:30] WARNING: not removing hydrogen atom without neighbors\n 87% 1766/2039 [01:09&lt;00:08, 32.14it/s][21:05:31] WARNING: not removing hydrogen atom without neighbors\n[21:05:31] WARNING: not removing hydrogen atom without neighbors\n 88% 1792/2039 [01:10&lt;00:09, 25.06it/s][21:05:32] WARNING: not removing hydrogen atom without neighbors\n 92% 1870/2039 [01:13&lt;00:05, 30.02it/s][21:05:35] WARNING: not removing hydrogen atom without neighbors\n 93% 1896/2039 [01:14&lt;00:05, 27.70it/s][21:05:36] WARNING: not removing hydrogen atom without neighbors\n 95% 1947/2039 [01:16&lt;00:03, 24.29it/s][21:05:38] WARNING: not removing hydrogen atom without neighbors\n 97% 1976/2039 [01:17&lt;00:02, 29.55it/s][21:05:39] WARNING: not removing hydrogen atom without neighbors\n100% 2039/2039 [01:19&lt;00:00, 25.67it/s]\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Finetuning with existing data\n     <a class="anchor-link" href="#Finetuning-with-existing-data">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     Given the labelled dataset and the molecular features, we can use\n     <code>\n      finetune\n     </code>\n     function to finetune the pretrained model.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[10]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="n">finetune</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">csv</span> \\\n                        <span class="o">--</span><span class="n">features_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">npz</span> \\\n                        <span class="o">--</span><span class="n">save_dir</span> <span class="n">model</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">/</span> \\\n                        <span class="o">--</span><span class="n">checkpoint_path</span> <span class="n">model</span><span class="o">/</span><span class="n">tryout</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">ep3</span> \\\n                        <span class="o">--</span><span class="n">dataset_type</span> <span class="n">classification</span> \\\n                        <span class="o">--</span><span class="n">split_type</span> <span class="n">scaffold_balanced</span> \\\n                        <span class="o">--</span><span class="n">ensemble_size</span> <span class="mi">1</span> \\\n                        <span class="o">--</span><span class="n">num_folds</span> <span class="mi">3</span> \\\n                        <span class="o">--</span><span class="n">no_features_scaling</span> \\\n                        <span class="o">--</span><span class="n">ffn_hidden_size</span> <span class="mi">200</span> \\\n                        <span class="o">--</span><span class="n">batch_size</span> <span class="mi">32</span> \\\n                        <span class="o">--</span><span class="n">epochs</span> <span class="mi">10</span> \\\n                        <span class="o">--</span><span class="n">init_lr</span> <span class="mf">0.00015</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\n[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\nFold 0\nLoading data\nNumber of tasks = 1\nSplitting data with seed 0\n100% 2039/2039 [00:00&lt;00:00, 3681.51it/s]\nTotal scaffolds = 1,025 | train scaffolds = 764 | val scaffolds = 123 | test scaffolds = 138\nLabel averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels: [(array([0.72992701]), array([137])), (array([1.]), array([1])), (array([0.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1])), (array([0.]), array([1])), (array([1.]), array([1])), (array([1.]), array([2])), (array([0.]), array([2])), (array([1.]), array([1]))]\nClass sizes\np_np 0: 23.49%, 1: 76.51%\nTotal size = 2,039 | train size = 1,631 | val size = 203 | test size = 205\nLoading model 0 from model/tryout/model.ep3\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nPretrained parameter "av_task_atom.linear.weight" cannot be found in model parameters.\nPretrained parameter "av_task_atom.linear.bias" cannot be found in model parameters.\nPretrained parameter "av_task_bond.linear.weight" cannot be found in model parameters.\nPretrained parameter "av_task_bond.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear_rev.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear_rev.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear_rev.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear_rev.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.readout.cached_zero_vector" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_atom.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_atom.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_bond.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_bond.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_atom.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_atom.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_bond.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_bond.bias" cannot be found in model parameters.\nGroverFinetuneTask(\n  (grover): GROVEREmbedding(\n    (encoders): GTransEncoder(\n      (edge_blocks): ModuleList(\n        (0): MTBlock(\n          (heads): ModuleList(\n            (0): Head(\n              (mpn_q): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_k): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_v): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n            )\n          )\n          (act_func): PReLU(num_parameters=1)\n          (dropout_layer): Dropout(p=0.1, inplace=False)\n          (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (W_i): Linear(in_features=165, out_features=100, bias=False)\n          (attn): MultiHeadedAttention(\n            (linear_layers): ModuleList(\n              (0): Linear(in_features=100, out_features=100, bias=True)\n              (1): Linear(in_features=100, out_features=100, bias=True)\n              (2): Linear(in_features=100, out_features=100, bias=True)\n            )\n            (output_linear): Linear(in_features=100, out_features=100, bias=False)\n            (attention): Attention()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (W_o): Linear(in_features=100, out_features=100, bias=False)\n          (sublayer): SublayerConnection(\n            (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (node_blocks): ModuleList(\n        (0): MTBlock(\n          (heads): ModuleList(\n            (0): Head(\n              (mpn_q): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_k): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_v): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n            )\n          )\n          (act_func): PReLU(num_parameters=1)\n          (dropout_layer): Dropout(p=0.1, inplace=False)\n          (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (W_i): Linear(in_features=151, out_features=100, bias=False)\n          (attn): MultiHeadedAttention(\n            (linear_layers): ModuleList(\n              (0): Linear(in_features=100, out_features=100, bias=True)\n              (1): Linear(in_features=100, out_features=100, bias=True)\n              (2): Linear(in_features=100, out_features=100, bias=True)\n            )\n            (output_linear): Linear(in_features=100, out_features=100, bias=False)\n            (attention): Attention()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (W_o): Linear(in_features=100, out_features=100, bias=False)\n          (sublayer): SublayerConnection(\n            (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ffn_atom_from_atom): PositionwiseFeedForward(\n        (W_1): Linear(in_features=251, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_atom_from_bond): PositionwiseFeedForward(\n        (W_1): Linear(in_features=251, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_bond_from_atom): PositionwiseFeedForward(\n        (W_1): Linear(in_features=265, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_bond_from_bond): PositionwiseFeedForward(\n        (W_1): Linear(in_features=265, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (atom_from_atom_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (atom_from_bond_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (bond_from_atom_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (bond_from_bond_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (act_func_node): PReLU(num_parameters=1)\n      (act_func_edge): PReLU(num_parameters=1)\n      (dropout_layer): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (readout): Readout()\n  (mol_atom_from_atom_ffn): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=300, out_features=200, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=200, out_features=1, bias=True)\n  )\n  (mol_atom_from_bond_ffn): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=300, out_features=200, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=200, out_features=1, bias=True)\n  )\n  (sigmoid): Sigmoid()\n)\nNumber of parameters = 889,418\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0000 loss_train: 1.027524 loss_val: 0.494863 auc_val: 0.8744 cur_lr: 0.00059 t_time: 5.5550s v_time: 0.7379s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0001 loss_train: 0.855072 loss_val: 0.488093 auc_val: 0.8805 cur_lr: 0.00098 t_time: 5.4703s v_time: 0.7435s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0002 loss_train: 0.802001 loss_val: 0.488020 auc_val: 0.8953 cur_lr: 0.00073 t_time: 5.5585s v_time: 0.7317s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0003 loss_train: 0.743282 loss_val: 0.483438 auc_val: 0.8804 cur_lr: 0.00055 t_time: 5.5933s v_time: 0.7305s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0004 loss_train: 0.705130 loss_val: 0.473394 auc_val: 0.9043 cur_lr: 0.00041 t_time: 5.5970s v_time: 0.7558s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0005 loss_train: 0.682583 loss_val: 0.473367 auc_val: 0.8962 cur_lr: 0.00030 t_time: 5.5740s v_time: 0.7244s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0006 loss_train: 0.659755 loss_val: 0.477886 auc_val: 0.8939 cur_lr: 0.00023 t_time: 5.5852s v_time: 0.7288s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0007 loss_train: 0.658016 loss_val: 0.476979 auc_val: 0.8923 cur_lr: 0.00017 t_time: 5.5050s v_time: 0.7280s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0008 loss_train: 0.647427 loss_val: 0.470443 auc_val: 0.9020 cur_lr: 0.00013 t_time: 5.5287s v_time: 0.7295s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0009 loss_train: 0.646125 loss_val: 0.474078 auc_val: 0.8938 cur_lr: 0.00010 t_time: 5.7616s v_time: 0.7285s\nModel 0 best validation auc = 0.904320 on epoch 4\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nLoading pretrained parameter "readout.cached_zero_vector".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_atom_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.bias".\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nModel 0 test auc = 0.921247\nEnsemble test auc = 0.921247\nFold 1\nLoading data\nNumber of tasks = 1\nSplitting data with seed 1\n100% 2039/2039 [00:00&lt;00:00, 3551.50it/s]\nTotal scaffolds = 1,025 | train scaffolds = 768 | val scaffolds = 132 | test scaffolds = 125\nLabel averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels: [(array([0.72992701]), array([137])), (array([1.]), array([2])), (array([1.]), array([3])), (array([0.8]), array([5])), (array([1.]), array([9])), (array([1.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1]))]\nClass sizes\np_np 0: 23.49%, 1: 76.51%\nTotal size = 2,039 | train size = 1,631 | val size = 203 | test size = 205\nLoading model 0 from model/tryout/model.ep3\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nPretrained parameter "av_task_atom.linear.weight" cannot be found in model parameters.\nPretrained parameter "av_task_atom.linear.bias" cannot be found in model parameters.\nPretrained parameter "av_task_bond.linear.weight" cannot be found in model parameters.\nPretrained parameter "av_task_bond.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear_rev.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear_rev.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear_rev.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear_rev.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.readout.cached_zero_vector" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_atom.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_atom.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_bond.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_bond.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_atom.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_atom.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_bond.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_bond.bias" cannot be found in model parameters.\nGroverFinetuneTask(\n  (grover): GROVEREmbedding(\n    (encoders): GTransEncoder(\n      (edge_blocks): ModuleList(\n        (0): MTBlock(\n          (heads): ModuleList(\n            (0): Head(\n              (mpn_q): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_k): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_v): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n            )\n          )\n          (act_func): PReLU(num_parameters=1)\n          (dropout_layer): Dropout(p=0.1, inplace=False)\n          (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (W_i): Linear(in_features=165, out_features=100, bias=False)\n          (attn): MultiHeadedAttention(\n            (linear_layers): ModuleList(\n              (0): Linear(in_features=100, out_features=100, bias=True)\n              (1): Linear(in_features=100, out_features=100, bias=True)\n              (2): Linear(in_features=100, out_features=100, bias=True)\n            )\n            (output_linear): Linear(in_features=100, out_features=100, bias=False)\n            (attention): Attention()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (W_o): Linear(in_features=100, out_features=100, bias=False)\n          (sublayer): SublayerConnection(\n            (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (node_blocks): ModuleList(\n        (0): MTBlock(\n          (heads): ModuleList(\n            (0): Head(\n              (mpn_q): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_k): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_v): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n            )\n          )\n          (act_func): PReLU(num_parameters=1)\n          (dropout_layer): Dropout(p=0.1, inplace=False)\n          (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (W_i): Linear(in_features=151, out_features=100, bias=False)\n          (attn): MultiHeadedAttention(\n            (linear_layers): ModuleList(\n              (0): Linear(in_features=100, out_features=100, bias=True)\n              (1): Linear(in_features=100, out_features=100, bias=True)\n              (2): Linear(in_features=100, out_features=100, bias=True)\n            )\n            (output_linear): Linear(in_features=100, out_features=100, bias=False)\n            (attention): Attention()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (W_o): Linear(in_features=100, out_features=100, bias=False)\n          (sublayer): SublayerConnection(\n            (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ffn_atom_from_atom): PositionwiseFeedForward(\n        (W_1): Linear(in_features=251, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_atom_from_bond): PositionwiseFeedForward(\n        (W_1): Linear(in_features=251, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_bond_from_atom): PositionwiseFeedForward(\n        (W_1): Linear(in_features=265, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_bond_from_bond): PositionwiseFeedForward(\n        (W_1): Linear(in_features=265, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (atom_from_atom_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (atom_from_bond_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (bond_from_atom_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (bond_from_bond_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (act_func_node): PReLU(num_parameters=1)\n      (act_func_edge): PReLU(num_parameters=1)\n      (dropout_layer): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (readout): Readout()\n  (mol_atom_from_atom_ffn): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=300, out_features=200, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=200, out_features=1, bias=True)\n  )\n  (mol_atom_from_bond_ffn): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=300, out_features=200, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=200, out_features=1, bias=True)\n  )\n  (sigmoid): Sigmoid()\n)\nNumber of parameters = 889,418\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0000 loss_train: 1.016377 loss_val: 0.492704 auc_val: 0.8791 cur_lr: 0.00059 t_time: 6.3182s v_time: 0.7794s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0001 loss_train: 0.822924 loss_val: 0.487600 auc_val: 0.8680 cur_lr: 0.00098 t_time: 5.5121s v_time: 0.7989s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0002 loss_train: 0.752341 loss_val: 0.470391 auc_val: 0.8893 cur_lr: 0.00073 t_time: 5.5443s v_time: 0.7647s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0003 loss_train: 0.709847 loss_val: 0.468552 auc_val: 0.8863 cur_lr: 0.00055 t_time: 5.6165s v_time: 0.8104s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0004 loss_train: 0.682037 loss_val: 0.463301 auc_val: 0.8895 cur_lr: 0.00041 t_time: 5.5689s v_time: 0.7795s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0005 loss_train: 0.659133 loss_val: 0.464382 auc_val: 0.8914 cur_lr: 0.00030 t_time: 5.5949s v_time: 0.8020s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0006 loss_train: 0.630823 loss_val: 0.463676 auc_val: 0.8871 cur_lr: 0.00023 t_time: 5.5311s v_time: 0.7548s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0007 loss_train: 0.613836 loss_val: 0.460376 auc_val: 0.8912 cur_lr: 0.00017 t_time: 5.5768s v_time: 0.7511s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0008 loss_train: 0.604636 loss_val: 0.464385 auc_val: 0.8900 cur_lr: 0.00013 t_time: 5.5764s v_time: 0.7848s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0009 loss_train: 0.600993 loss_val: 0.461464 auc_val: 0.8902 cur_lr: 0.00010 t_time: 5.6025s v_time: 0.7736s\nModel 0 best validation auc = 0.891352 on epoch 5\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nLoading pretrained parameter "readout.cached_zero_vector".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_atom_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.bias".\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nModel 0 test auc = 0.920000\nEnsemble test auc = 0.920000\nFold 2\nLoading data\nNumber of tasks = 1\nSplitting data with seed 2\n100% 2039/2039 [00:00&lt;00:00, 3569.05it/s]\nTotal scaffolds = 1,025 | train scaffolds = 766 | val scaffolds = 125 | test scaffolds = 134\nLabel averages per scaffold, in decreasing order of scaffold frequency,capped at 10 scaffolds and 20 labels: [(array([0.72992701]), array([137])), (array([1.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1])), (array([0.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1])), (array([1.]), array([1])), (array([0.]), array([5])), (array([1.]), array([1]))]\nClass sizes\np_np 0: 23.49%, 1: 76.51%\nTotal size = 2,039 | train size = 1,631 | val size = 203 | test size = 205\nLoading model 0 from model/tryout/model.ep3\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nPretrained parameter "av_task_atom.linear.weight" cannot be found in model parameters.\nPretrained parameter "av_task_atom.linear.bias" cannot be found in model parameters.\nPretrained parameter "av_task_bond.linear.weight" cannot be found in model parameters.\nPretrained parameter "av_task_bond.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear_rev.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_atom.linear_rev.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear.bias" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear_rev.weight" cannot be found in model parameters.\nPretrained parameter "bv_task_bond.linear_rev.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.readout.cached_zero_vector" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_atom.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_atom.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_bond.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_atom_from_bond.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_atom.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_atom.bias" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_bond.weight" cannot be found in model parameters.\nPretrained parameter "fg_task_all.linear_bond_from_bond.bias" cannot be found in model parameters.\nGroverFinetuneTask(\n  (grover): GROVEREmbedding(\n    (encoders): GTransEncoder(\n      (edge_blocks): ModuleList(\n        (0): MTBlock(\n          (heads): ModuleList(\n            (0): Head(\n              (mpn_q): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_k): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_v): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n            )\n          )\n          (act_func): PReLU(num_parameters=1)\n          (dropout_layer): Dropout(p=0.1, inplace=False)\n          (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (W_i): Linear(in_features=165, out_features=100, bias=False)\n          (attn): MultiHeadedAttention(\n            (linear_layers): ModuleList(\n              (0): Linear(in_features=100, out_features=100, bias=True)\n              (1): Linear(in_features=100, out_features=100, bias=True)\n              (2): Linear(in_features=100, out_features=100, bias=True)\n            )\n            (output_linear): Linear(in_features=100, out_features=100, bias=False)\n            (attention): Attention()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (W_o): Linear(in_features=100, out_features=100, bias=False)\n          (sublayer): SublayerConnection(\n            (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (node_blocks): ModuleList(\n        (0): MTBlock(\n          (heads): ModuleList(\n            (0): Head(\n              (mpn_q): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_k): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n              (mpn_v): MPNEncoder(\n                (dropout_layer): Dropout(p=0.1, inplace=False)\n                (act_func): PReLU(num_parameters=1)\n                (W_h): Linear(in_features=100, out_features=100, bias=False)\n              )\n            )\n          )\n          (act_func): PReLU(num_parameters=1)\n          (dropout_layer): Dropout(p=0.1, inplace=False)\n          (layernorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n          (W_i): Linear(in_features=151, out_features=100, bias=False)\n          (attn): MultiHeadedAttention(\n            (linear_layers): ModuleList(\n              (0): Linear(in_features=100, out_features=100, bias=True)\n              (1): Linear(in_features=100, out_features=100, bias=True)\n              (2): Linear(in_features=100, out_features=100, bias=True)\n            )\n            (output_linear): Linear(in_features=100, out_features=100, bias=False)\n            (attention): Attention()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (W_o): Linear(in_features=100, out_features=100, bias=False)\n          (sublayer): SublayerConnection(\n            (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ffn_atom_from_atom): PositionwiseFeedForward(\n        (W_1): Linear(in_features=251, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_atom_from_bond): PositionwiseFeedForward(\n        (W_1): Linear(in_features=251, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_bond_from_atom): PositionwiseFeedForward(\n        (W_1): Linear(in_features=265, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (ffn_bond_from_bond): PositionwiseFeedForward(\n        (W_1): Linear(in_features=265, out_features=400, bias=True)\n        (W_2): Linear(in_features=400, out_features=100, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (act_func): PReLU(num_parameters=1)\n      )\n      (atom_from_atom_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (atom_from_bond_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (bond_from_atom_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (bond_from_bond_sublayer): SublayerConnection(\n        (norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (act_func_node): PReLU(num_parameters=1)\n      (act_func_edge): PReLU(num_parameters=1)\n      (dropout_layer): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (readout): Readout()\n  (mol_atom_from_atom_ffn): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=300, out_features=200, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=200, out_features=1, bias=True)\n  )\n  (mol_atom_from_bond_ffn): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=300, out_features=200, bias=True)\n    (2): PReLU(num_parameters=1)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=200, out_features=1, bias=True)\n  )\n  (sigmoid): Sigmoid()\n)\nNumber of parameters = 889,418\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0000 loss_train: 1.000364 loss_val: 0.507716 auc_val: 0.8434 cur_lr: 0.00059 t_time: 5.7976s v_time: 0.7802s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0001 loss_train: 0.824395 loss_val: 0.504539 auc_val: 0.8560 cur_lr: 0.00098 t_time: 5.5894s v_time: 0.7779s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0002 loss_train: 0.735137 loss_val: 0.493423 auc_val: 0.8539 cur_lr: 0.00073 t_time: 5.5191s v_time: 0.7610s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0003 loss_train: 0.687535 loss_val: 0.487282 auc_val: 0.8597 cur_lr: 0.00055 t_time: 5.5613s v_time: 0.7595s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0004 loss_train: 0.681197 loss_val: 0.489330 auc_val: 0.8702 cur_lr: 0.00041 t_time: 5.5513s v_time: 0.7501s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0005 loss_train: 0.647608 loss_val: 0.488870 auc_val: 0.8618 cur_lr: 0.00030 t_time: 5.6565s v_time: 0.7739s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0006 loss_train: 0.638494 loss_val: 0.488281 auc_val: 0.8729 cur_lr: 0.00023 t_time: 5.5400s v_time: 0.7584s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0007 loss_train: 0.626862 loss_val: 0.490144 auc_val: 0.8702 cur_lr: 0.00017 t_time: 5.6183s v_time: 0.7814s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0008 loss_train: 0.619776 loss_val: 0.484179 auc_val: 0.8782 cur_lr: 0.00013 t_time: 5.9662s v_time: 0.7596s\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nEpoch: 0009 loss_train: 0.613262 loss_val: 0.486484 auc_val: 0.8789 cur_lr: 0.00010 t_time: 6.3030s v_time: 0.7931s\nModel 0 best validation auc = 0.878887 on epoch 9\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nLoading pretrained parameter "readout.cached_zero_vector".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_atom_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.bias".\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\nModel 0 test auc = 0.888635\nEnsemble test auc = 0.888635\n3-fold cross validation\nSeed 0 ==&gt; test auc = 0.921247\nSeed 1 ==&gt; test auc = 0.920000\nSeed 2 ==&gt; test auc = 0.888635\noverall_scaffold_balanced_test_auc=0.909961\nstd=0.015088\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h1>\n     Predicting output\n     <a class="anchor-link" href="#Predicting-output">\n      \xb6\n     </a>\n    </h1>\n    <h2>\n     Extracting molecular features\n     <a class="anchor-link" href="#Extracting-molecular-features">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     If the finetuned model uses the molecular feature as input, we need to generate the molecular feature for the target molecules as well.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[11]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">scripts</span><span class="o">/</span><span class="n">save_features</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">csv</span> \\\n                                <span class="o">--</span><span class="n">save_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">npz</span> \\\n                                <span class="o">--</span><span class="n">features_generator</span> <span class="n">rdkit_2d_normalized</span> \\\n                                <span class="o">--</span><span class="n">restart</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n[21:09:19] WARNING: not removing hydrogen atom without neighbors\n  0% 6/2039 [00:01&lt;06:32,  5.18it/s][21:09:21] WARNING: not removing hydrogen atom without neighbors\n  2% 47/2039 [00:02&lt;01:03, 31.22it/s][21:09:22] WARNING: not removing hydrogen atom without neighbors\n  4% 91/2039 [00:04&lt;01:14, 26.15it/s][21:09:24] WARNING: not removing hydrogen atom without neighbors\n  6% 120/2039 [00:05&lt;01:03, 30.16it/s][21:09:25] WARNING: not removing hydrogen atom without neighbors\n  8% 161/2039 [00:07&lt;01:14, 25.26it/s][21:09:27] WARNING: not removing hydrogen atom without neighbors\n  8% 169/2039 [00:08&lt;02:01, 15.42it/s][21:09:28] WARNING: not removing hydrogen atom without neighbors\n[21:09:28] WARNING: not removing hydrogen atom without neighbors\n 10% 198/2039 [00:08&lt;01:00, 30.28it/s][21:09:29] WARNING: not removing hydrogen atom without neighbors\n 13% 265/2039 [00:10&lt;00:55, 32.07it/s][21:09:31] WARNING: not removing hydrogen atom without neighbors\n[21:09:31] WARNING: not removing hydrogen atom without neighbors\n[21:09:31] WARNING: not removing hydrogen atom without neighbors\n 15% 305/2039 [00:12&lt;01:07, 25.66it/s][21:09:32] WARNING: not removing hydrogen atom without neighbors\n[21:09:32] WARNING: not removing hydrogen atom without neighbors\n[21:09:32] WARNING: not removing hydrogen atom without neighbors\n 20% 417/2039 [00:16&lt;00:46, 35.03it/s][21:09:37] WARNING: not removing hydrogen atom without neighbors\n[21:09:37] WARNING: not removing hydrogen atom without neighbors\n[21:09:38] WARNING: not removing hydrogen atom without neighbors\n 23% 464/2039 [00:18&lt;00:48, 32.41it/s][21:09:39] WARNING: not removing hydrogen atom without neighbors\n 26% 529/2039 [00:21&lt;00:52, 28.80it/s][21:09:41] WARNING: not removing hydrogen atom without neighbors\n 27% 552/2039 [00:22&lt;00:56, 26.22it/s][21:09:42] WARNING: not removing hydrogen atom without neighbors\n 28% 570/2039 [00:22&lt;00:58, 25.26it/s][21:09:42] WARNING: not removing hydrogen atom without neighbors\n 29% 600/2039 [00:23&lt;00:55, 25.71it/s][21:09:43] WARNING: not removing hydrogen atom without neighbors\n 30% 619/2039 [00:24&lt;00:55, 25.71it/s][21:09:44] WARNING: not removing hydrogen atom without neighbors\n[21:09:44] WARNING: not removing hydrogen atom without neighbors\n 32% 645/2039 [00:25&lt;00:49, 28.14it/s][21:09:45] WARNING: not removing hydrogen atom without neighbors\n[21:09:45] WARNING: not removing hydrogen atom without neighbors\n 34% 687/2039 [00:27&lt;00:57, 23.64it/s][21:09:47] WARNING: not removing hydrogen atom without neighbors\n 35% 714/2039 [00:28&lt;00:57, 23.01it/s][21:09:48] WARNING: not removing hydrogen atom without neighbors\n 39% 798/2039 [00:31&lt;00:58, 21.09it/s][21:09:53] WARNING: not removing hydrogen atom without neighbors\n 40% 813/2039 [00:33&lt;01:37, 12.61it/s][21:09:54] WARNING: not removing hydrogen atom without neighbors\n 44% 897/2039 [00:36&lt;00:49, 23.10it/s][21:09:56] WARNING: not removing hydrogen atom without neighbors\n 44% 903/2039 [00:36&lt;00:49, 22.76it/s][21:09:57] WARNING: not removing hydrogen atom without neighbors\n 45% 919/2039 [00:37&lt;00:44, 25.44it/s][21:09:58] WARNING: not removing hydrogen atom without neighbors\n[21:09:58] [21:09:58] WARNING: not removing hydrogen atom without neighbors\nWARNING: not removing hydrogen atom without neighbors\n[21:09:59] WARNING: not removing hydrogen atom without neighbors\n 50% 1013/2039 [00:41&lt;00:33, 30.69it/s][21:10:01] WARNING: not removing hydrogen atom without neighbors\n 51% 1041/2039 [00:42&lt;00:34, 29.09it/s][21:10:02] WARNING: not removing hydrogen atom without neighbors\n 56% 1135/2039 [00:45&lt;00:36, 24.64it/s][21:10:05] WARNING: not removing hydrogen atom without neighbors\n 57% 1153/2039 [00:46&lt;00:35, 24.77it/s][21:10:06] WARNING: not removing hydrogen atom without neighbors\n 57% 1161/2039 [00:46&lt;00:28, 30.81it/s][21:10:07] WARNING: not removing hydrogen atom without neighbors\n 57% 1168/2039 [00:47&lt;00:36, 23.87it/s][21:10:07] WARNING: not removing hydrogen atom without neighbors\n 58% 1186/2039 [00:47&lt;00:25, 33.33it/s][21:10:07] WARNING: not removing hydrogen atom without neighbors\n 59% 1194/2039 [00:48&lt;00:26, 32.07it/s][21:10:08] WARNING: not removing hydrogen atom without neighbors\n 61% 1235/2039 [00:49&lt;00:38, 21.11it/s][21:10:10] WARNING: not removing hydrogen atom without neighbors\n 62% 1263/2039 [00:51&lt;00:32, 24.19it/s][21:10:11] WARNING: not removing hydrogen atom without neighbors\n[21:10:11] WARNING: not removing hydrogen atom without neighbors\n 62% 1268/2039 [00:51&lt;00:32, 24.06it/s][21:10:11] WARNING: not removing hydrogen atom without neighbors\n 63% 1292/2039 [00:52&lt;00:28, 26.37it/s][21:10:12] WARNING: not removing hydrogen atom without neighbors\n[21:10:12] WARNING: not removing hydrogen atom without neighbors\n 64% 1296/2039 [00:52&lt;00:30, 24.41it/s][21:10:12] WARNING: not removing hydrogen atom without neighbors\n 64% 1308/2039 [00:52&lt;00:27, 26.72it/s][21:10:12] WARNING: not removing hydrogen atom without neighbors\n 65% 1318/2039 [00:53&lt;00:31, 22.61it/s][21:10:13] WARNING: not removing hydrogen atom without neighbors\n 65% 1334/2039 [00:53&lt;00:22, 31.22it/s][21:10:13] WARNING: not removing hydrogen atom without neighbors\n 67% 1356/2039 [00:54&lt;00:36, 18.90it/s][21:10:14] WARNING: not removing hydrogen atom without neighbors\n 68% 1384/2039 [00:55&lt;00:36, 17.78it/s][21:10:15] WARNING: not removing hydrogen atom without neighbors\n 71% 1442/2039 [00:57&lt;00:27, 22.02it/s][21:10:18] WARNING: not removing hydrogen atom without neighbors\n 71% 1448/2039 [00:58&lt;00:27, 21.47it/s][21:10:18] WARNING: not removing hydrogen atom without neighbors\n 72% 1465/2039 [00:58&lt;00:19, 29.81it/s][21:10:19] WARNING: not removing hydrogen atom without neighbors\n 72% 1472/2039 [00:59&lt;00:26, 21.40it/s][21:10:19] WARNING: not removing hydrogen atom without neighbors\n 77% 1567/2039 [01:02&lt;00:22, 21.35it/s][21:10:22] WARNING: not removing hydrogen atom without neighbors\n 78% 1587/2039 [01:03&lt;00:13, 33.18it/s][21:10:23] WARNING: not removing hydrogen atom without neighbors\n 78% 1591/2039 [01:03&lt;00:20, 21.92it/s][21:10:23] WARNING: not removing hydrogen atom without neighbors\n 78% 1594/2039 [01:03&lt;00:20, 21.43it/s]WARNING: not removing hydrogen atom without neighbors\n 79% 1616/2039 [01:04&lt;00:15, 26.99it/s][21:10:24] WARNING: not removing hydrogen atom without neighbors\n 79% 1620/2039 [01:04&lt;00:19, 21.72it/s][21:10:24] WARNING: not removing hydrogen atom without neighbors\n 81% 1659/2039 [01:06&lt;00:16, 23.11it/s][21:10:26] WARNING: not removing hydrogen atom without neighbors\n 82% 1671/2039 [01:06&lt;00:13, 28.20it/s][21:10:26] WARNING: not removing hydrogen atom without neighbors\n 83% 1686/2039 [01:07&lt;00:14, 23.67it/s][21:10:27] WARNING: not removing hydrogen atom without neighbors\n[21:10:27] WARNING: not removing hydrogen atom without neighbors\n 83% 1689/2039 [01:07&lt;00:17, 19.68it/s][21:10:27] WARNING: not removing hydrogen atom without neighbors\n 84% 1712/2039 [01:08&lt;00:14, 22.21it/s][21:10:28] WARNING: not removing hydrogen atom without neighbors\n 85% 1736/2039 [01:09&lt;00:09, 31.18it/s][21:10:29] WARNING: not removing hydrogen atom without neighbors\n 87% 1766/2039 [01:10&lt;00:08, 32.87it/s][21:10:30] WARNING: not removing hydrogen atom without neighbors\n[21:10:30] WARNING: not removing hydrogen atom without neighbors\n 88% 1797/2039 [01:11&lt;00:08, 29.30it/s][21:10:31] WARNING: not removing hydrogen atom without neighbors\n 92% 1870/2039 [01:14&lt;00:06, 26.35it/s][21:10:34] WARNING: not removing hydrogen atom without neighbors\n 93% 1896/2039 [01:15&lt;00:05, 26.27it/s][21:10:35] WARNING: not removing hydrogen atom without neighbors\n 96% 1948/2039 [01:17&lt;00:03, 27.22it/s][21:10:37] WARNING: not removing hydrogen atom without neighbors\n 97% 1971/2039 [01:18&lt;00:02, 26.46it/s][21:10:38] WARNING: not removing hydrogen atom without neighbors\n100% 2039/2039 [01:20&lt;00:00, 25.38it/s]\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Predicting output with the finetuned model\n     <a class="anchor-link" href="#Predicting-output-with-the-finetuned-model">\n      \xb6\n     </a>\n    </h2>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[12]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-python">\n      <pre class="overflow-x-scroll"><span></span><span class="err">!</span><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="n">predict</span> <span class="o">--</span><span class="n">data_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">csv</span> \\\n               <span class="o">--</span><span class="n">features_path</span> <span class="n">exampledata</span><span class="o">/</span><span class="n">finetune</span><span class="o">/</span><span class="n">bbbp</span><span class="o">.</span><span class="n">npz</span> \\\n               <span class="o">--</span><span class="n">checkpoint_dir</span> <span class="o">./</span><span class="n">model</span> \\\n               <span class="o">--</span><span class="n">no_features_scaling</span> \\\n               <span class="o">--</span><span class="n">output</span> <span class="n">data_pre</span><span class="o">.</span><span class="n">csv</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">WARNING:root:No normalization for BCUT2D_MWHI\nWARNING:root:No normalization for BCUT2D_MWLOW\nWARNING:root:No normalization for BCUT2D_CHGHI\nWARNING:root:No normalization for BCUT2D_CHGLO\nWARNING:root:No normalization for BCUT2D_LOGPHI\nWARNING:root:No normalization for BCUT2D_LOGPLOW\nWARNING:root:No normalization for BCUT2D_MRHI\nWARNING:root:No normalization for BCUT2D_MRLOW\n[WARNING] Horovod cannot be imported; multi-GPU training is unsupported\nLoading training args\nLoading data\nValidating SMILES\nTest size = 2,039\nPredicting...\n  0% 0/3 [00:00&lt;?, ?it/s]Loading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nLoading pretrained parameter "readout.cached_zero_vector".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_atom_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.bias".\nMoving model to cuda\n/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n 33% 1/3 [00:08&lt;00:17,  8.86s/it]Loading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nLoading pretrained parameter "readout.cached_zero_vector".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_atom_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.bias".\nMoving model to cuda\n 67% 2/3 [00:13&lt;00:06,  6.60s/it]Loading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.edge_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_q.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_k.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.heads.0.mpn_v.W_h.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.act_func.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.layernorm.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_i.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.0.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.1.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.linear_layers.2.bias".\nLoading pretrained parameter "grover.encoders.node_blocks.0.attn.output_linear.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.W_o.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.node_blocks.0.sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_atom_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_atom.act_func.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_1.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.weight".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.W_2.bias".\nLoading pretrained parameter "grover.encoders.ffn_bond_from_bond.act_func.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.atom_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_atom_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.weight".\nLoading pretrained parameter "grover.encoders.bond_from_bond_sublayer.norm.bias".\nLoading pretrained parameter "grover.encoders.act_func_node.weight".\nLoading pretrained parameter "grover.encoders.act_func_edge.weight".\nLoading pretrained parameter "readout.cached_zero_vector".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_atom_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_atom_ffn.4.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.1.bias".\nLoading pretrained parameter "mol_atom_from_bond_ffn.2.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.weight".\nLoading pretrained parameter "mol_atom_from_bond_ffn.4.bias".\nMoving model to cuda\n100% 3/3 [00:18&lt;00:00,  6.29s/it]\nSaving predictions to data_pre.csv\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Output\n     <a class="anchor-link" href="#Output">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     The output will be saved in a file called\n     <code>\n      data_pre.csv\n     </code>\n     .\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h1>\n     Congratulations! Time to join the Community!\n     <a class="anchor-link" href="#Congratulations!-Time-to-join-the-Community!">\n      \xb6\n     </a>\n    </h1>\n    <p>\n     Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n    </p>\n    <h1>\n     <strong>\n      Star DeepChem on\n      <a href="https://github.com/deepchem/deepchem">\n       Github\n      </a>\n     </strong>\n     <a class="anchor-link" href="#Star-DeepChem-on-Github">\n      \xb6\n     </a>\n    </h1>\n    <p>\n     This helps build awareness of the DeepChem project and the tools for open source drug discovery that we\'re trying to build.\n    </p>\n    <h1>\n     <strong>\n      Join the DeepChem Gitter\n     </strong>\n     <a class="anchor-link" href="#Join-the-DeepChem-Gitter">\n      \xb6\n     </a>\n    </h1>\n    <p>\n     The DeepChem\n     <a href="https://gitter.im/deepchem/Lobby">\n      Gitter\n     </a>\n     hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n'},i=n(7294),d=n(7466),p=n.n(d);let l=()=>((0,i.useEffect)(()=>{var e,r;null===(e=document.getElementsByClassName("scroll-nav")[0])||void 0===e||e.remove();let n=document.querySelector(".notebook"),a=document.querySelector(".notebook");a&&n&&p().init(n,{sections:"h1, h2",insertTarget:a,insertLocation:"after"}),null==MathJax||null===(r=MathJax.Hub)||void 0===r||r.Queue(["Typeset",MathJax.Hub])},[]),(0,a.jsx)("div",{className:"overflow-x-scroll",dangerouslySetInnerHTML:{__html:"".concat(s.html," ").concat(t.Z)}}));l.Layout=o.Z;var c=l}},function(e){e.O(0,[2443,9774,2888,179],function(){return e(e.s=6712)}),_N_E=e.O()}]);