(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[4387],{2342:function(s,a,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/tutorials/pytorchlightning-integration",function(){return n(1644)}])},1644:function(s,a,n){"use strict";n.r(a),n.d(a,{default:function(){return d}});var p=n(5893),e=n(1618),l=n(6485),t={html:'<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=945435b4">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h1>\n     Pytorch-Lightning Integration for DeepChem Models\n     <a class="anchor-link" href="#Pytorch-Lightning-Integration-for-DeepChem-Models">\n      \xb6\n     </a>\n    </h1>\n    <p>\n     In this tutorial we will go through how to setup a deepchem model inside the\n     <a href="https://www.pytorchlightning.ai/">\n      pytorch-lightning\n     </a>\n     framework. Lightning is a pytorch framework which simplifies the process of experimenting with pytorch models easier. A few key functionalities offered by pytorch lightning which deepchem users can find useful are:\n    </p>\n    <ol>\n     <li>\n      <p>\n       Multi-gpu training functionalities: pytorch-lightning provides easy multi-gpu, multi-node training. It also simplifies the process of launching multi-gpu, multi-node jobs across different cluster infrastructure, e.g. AWS, slurm based clusters.\n      </p>\n     </li>\n     <li>\n      <p>\n       Reducing boilerplate pytorch code: lightning takes care of details like,\n       <code>\n        optimizer.zero_grad(), model.train(), model.eval()\n       </code>\n       . Lightning also provides experiment logging functionality, for e.g. irrespective of training on CPU, GPU, multi-nodes the user can use the method\n       <code>\n        self.log\n       </code>\n       inside the trainer and it will appropriately log the metrics.\n      </p>\n     </li>\n     <li>\n      <p>\n       Features that can speed up training: half-precision training, gradient checkpointing, code profiling.\n      </p>\n     </li>\n    </ol>\n    <p>\n     <a href="https://colab.research.google.com/drive/1VVLqq0vMlPkSEXeqcFnHY_zEuvDOQu50?usp=sharing">\n      <img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/>\n     </a>\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bbb99230">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Setup\n     <a class="anchor-link" href="#Setup">\n      \xb6\n     </a>\n    </h2>\n    <ul>\n     <li>\n      This notebook assumes that you have already installed deepchem, if you have not follow the instructions at the deepchem installation page:\n      <a href="https://deepchem.readthedocs.io/en/latest/get_started/installation.html">\n       https://deepchem.readthedocs.io/en/latest/get_started/installation.html\n      </a>\n      .\n     </li>\n     <li>\n      Install pytorch lightning following the instructions on lightning\'s home page:\n      <a href="https://www.pytorchlightning.ai/">\n       https://www.pytorchlightning.ai/\n      </a>\n     </li>\n    </ul>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=ba6b1b0f">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[1]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="o">!</span>pip install --pre deepchem\n<span class="o">!</span>pip install pytorch_lightning\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">Requirement already satisfied: deepchem in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (2.6.1.dev20220119163852)\nRequirement already satisfied: numpy&gt;=1.21 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from deepchem) (1.22.0)\nRequirement already satisfied: scikit-learn in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from deepchem) (1.0.2)\nRequirement already satisfied: pandas in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from deepchem) (1.4.0)\nCollecting rdkit-pypi\n  Downloading rdkit_pypi-2021.9.5.1-cp38-cp38-macosx_11_0_arm64.whl (15.9 MB)\n     |████████████████████████████████| 15.9 MB 6.8 MB/s eta 0:00:01\nRequirement already satisfied: joblib in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from deepchem) (1.1.0)\nRequirement already satisfied: scipy in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from deepchem) (1.7.3)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from scikit-learn-&gt;deepchem) (3.0.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pandas-&gt;deepchem) (2.8.2)\nRequirement already satisfied: pytz&gt;=2020.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pandas-&gt;deepchem) (2021.3)\nRequirement already satisfied: Pillow in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from rdkit-pypi-&gt;deepchem) (8.4.0)\nRequirement already satisfied: six&gt;=1.5 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from python-dateutil&gt;=2.8.1-&gt;pandas-&gt;deepchem) (1.16.0)\nInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2021.9.5.1\nRequirement already satisfied: pytorch_lightning in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (1.5.8)\nRequirement already satisfied: typing-extensions in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (4.0.1)\nRequirement already satisfied: numpy&gt;=1.17.2 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (1.22.0)\nRequirement already satisfied: torch&gt;=1.7.* in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (1.10.2)\nRequirement already satisfied: tensorboard&gt;=2.2.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (2.7.0)\nRequirement already satisfied: tqdm&gt;=4.41.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (4.62.3)\nRequirement already satisfied: fsspec[http]!=2021.06.0,&gt;=2021.05.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (2022.1.0)\nRequirement already satisfied: packaging&gt;=17.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (21.3)\nRequirement already satisfied: PyYAML&gt;=5.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (6.0)\nRequirement already satisfied: pyDeprecate==0.3.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (0.3.1)\nProcessing /Users/princychahal/Library/Caches/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4/future-0.18.2-py3-none-any.whl\nRequirement already satisfied: torchmetrics&gt;=0.4.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pytorch_lightning) (0.7.0)\nRequirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (0.6.0)\nRequirement already satisfied: absl-py&gt;=0.4 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (1.0.0)\nRequirement already satisfied: grpcio&gt;=1.24.3 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (1.43.0)\nRequirement already satisfied: requests&lt;3,&gt;=2.21.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (2.27.1)\nRequirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (2.3.3)\nRequirement already satisfied: wheel&gt;=0.26 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (0.37.1)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (0.4.6)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (1.8.1)\nRequirement already satisfied: setuptools&gt;=41.0.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (60.5.0)\nRequirement already satisfied: werkzeug&gt;=0.11.15 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (2.0.2)\nRequirement already satisfied: markdown&gt;=2.6.8 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (3.3.6)\nRequirement already satisfied: protobuf&gt;=3.6.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (3.18.1)\nRequirement already satisfied: aiohttp; extra == "http" in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (3.8.1)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from packaging&gt;=17.0-&gt;pytorch_lightning) (3.0.7)\nRequirement already satisfied: six in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from absl-py&gt;=0.4-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (1.16.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (1.26.8)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version &gt;= "3" in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (2.0.10)\nRequirement already satisfied: idna&lt;4,&gt;=2.5; python_version &gt;= "3" in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (3.3)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (4.2.4)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (0.2.7)\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4; python_version &gt;= "3.6" in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (4.8)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (1.3.0)\nRequirement already satisfied: importlib-metadata&gt;=4.4; python_version &lt; "3.10" in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (4.10.1)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from aiohttp; extra == "http"-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (1.2.0)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from aiohttp; extra == "http"-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (1.2.0)\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from aiohttp; extra == "http"-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (4.0.2)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from aiohttp; extra == "http"-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (6.0.2)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from aiohttp; extra == "http"-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (1.7.2)\nRequirement already satisfied: attrs&gt;=17.3.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from aiohttp; extra == "http"-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch_lightning) (21.4.0)\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (0.4.8)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (3.1.1)\nRequirement already satisfied: zipp&gt;=0.5 in /Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages (from importlib-metadata&gt;=4.4; python_version &lt; "3.10"-&gt;markdown&gt;=2.6.8-&gt;tensorboard&gt;=2.2.0-&gt;pytorch_lightning) (3.7.0)\nInstalling collected packages: future\nSuccessfully installed future-0.18.2\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=98ee91c0">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     Import the relevant packages.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6890f523">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[2]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="kn">import</span> <span class="nn">deepchem</span> <span class="k">as</span> <span class="nn">dc</span>\n<span class="kn">from</span> <span class="nn">deepchem.models</span> <span class="kn">import</span> <span class="n">GCNModel</span>\n<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>\n<span class="kn">import</span> <span class="nn">torch</span>\n<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>\n<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>\n<span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>\n<span class="kn">from</span> <span class="nn">pytorch_lightning.core.lightning</span> <span class="kn">import</span> <span class="n">LightningModule</span>\n<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">Adam</span>\n<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>\n<span class="kn">import</span> <span class="nn">torch</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fe62d7c3">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Deepchem Example\n     <a class="anchor-link" href="#Deepchem-Example">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     Below we show an example of a Graph Convolution Network (GCN). Note that this is a simple example which uses a GCNModel to predict the label from an input sequence. We do not showcase the complete functionality of deepchem in this example as we want to restructure the deepchem code and adapt it so that it can be easily plugged into pytorch-lightning. This example was inspired from the\n     <code>\n      GCNModel\n     </code>\n     documentation present\n     <a href="https://github.com/deepchem/deepchem/blob/a68f8c072b80a1bce5671250aef60f9cc8519bec/deepchem/models/torch_models/gcn.py#L200">\n      here\n     </a>\n     .\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2859f97b">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Prepare the dataset\n     </strong>\n     : for training our deepchem models we need a dataset that we can use to train the model. Below we prepare a sample dataset for the purposes of this tutorial. Below we also directly use the featurized to encode examples for the dataset.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3789e1aa">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[3]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="n">smiles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"C1CCC1"</span><span class="p">,</span> <span class="s2">"CCC"</span><span class="p">]</span>\n<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]</span>\n<span class="n">featurizer</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">feat</span><span class="o">.</span><span class="n">MolGraphConvFeaturizer</span><span class="p">()</span>\n<span class="n">X</span> <span class="o">=</span> <span class="n">featurizer</span><span class="o">.</span><span class="n">featurize</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>\n<span class="n">dataset</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NumpyDataset</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3bc105a0">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Setup the model\n     </strong>\n     : now we initialize the Graph Convolutional Network model that we will use in our training.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=6d8fb2f9">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[4]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GCNModel</span><span class="p">(</span>\n    <span class="n">mode</span><span class="o">=</span><span class="s1">\'classification\'</span><span class="p">,</span>\n    <span class="n">n_tasks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>\n    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>\n    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span>\n<span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">\n     <pre class="overflow-x-scroll">[16:00:37] /Users/princychahal/Documents/github/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: Using backend: pytorch\ndlopen(/Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages/dgl-0.8-py3.8-macosx-11.0-arm64.egg/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.dylib, 1): image not found\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d5f76e7b">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Train the model\n     </strong>\n     : fit the model on our training dataset, also specify the number of epochs to run.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=4bdb2d8b">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[5]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>\n<span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">0.18830760717391967\n</pre>\n    </div>\n   </div>\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">\n     <pre class="overflow-x-scroll">/Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of \'cuda\', but CUDA is not available. Disabling\n  warnings.warn(\'User provided device_type of \\\'cuda\\\', but CUDA is not available. Disabling\')\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2f74d813">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Pytorch-Lightning + Deepchem example\n     <a class="anchor-link" href="#Pytorch-Lightning-+-Deepchem-example">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     Now we will look at an example of the GCN model adapt for Pytorch-Lightning. For using Pytorch-Lightning there are two important components:\n    </p>\n    <ol>\n     <li>\n      <code>\n       LightningDataModule\n      </code>\n      : This module defines who the data is prepared and fed into the model so that the model can use it for training. The module defines the train dataloader function which are directly used by the trainer to generate data for the\n      <code>\n       LightningModule\n      </code>\n      . To learn more about the\n      <code>\n       LightningDataModule\n      </code>\n      refer to the\n      <a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html">\n       datamodules documentation\n      </a>\n      .\n     </li>\n     <li>\n      <code>\n       LightningModule\n      </code>\n      : This module defines the training, validation steps for our model. We can use this module to initialize our model based on the hyperparameters. There are a number of boilerplate functions which we use directly to track our experiments, for example we can save all the hyperparameters that we used for training using the\n      <code>\n       self.save_hyperparameters()\n      </code>\n      method. For more details on how to use this module refer to the\n      <a href="https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html">\n       lightningmodules documentation\n      </a>\n      .\n     </li>\n    </ol>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=48b1523b">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Setup the torch dataset\n     </strong>\n     : Note that here we need to create a custome\n     <code>\n      SmilesDataset\n     </code>\n     so that we can easily interface with the deepchem featurizers. For this interface we need to define a collate method so that we can create batches for the dataset.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=0c16f761">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[6]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># prepare LightningDataModule</span>\n<span class="k">class</span> <span class="nc">SmilesDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>\n    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smiles</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>\n        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>\n        <span class="n">featurizer</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">feat</span><span class="o">.</span><span class="n">MolGraphConvFeaturizer</span><span class="p">()</span>\n        <span class="n">X</span> <span class="o">=</span> <span class="n">featurizer</span><span class="o">.</span><span class="n">featurize</span><span class="p">(</span><span class="n">smiles</span><span class="p">)</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">_samples</span> <span class="o">=</span> <span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NumpyDataset</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>\n        \n    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>\n        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_samples</span><span class="p">)</span>\n        \n    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>\n        <span class="k">return</span> <span class="p">(</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">_samples</span><span class="o">.</span><span class="n">X</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">_samples</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">_samples</span><span class="o">.</span><span class="n">w</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>\n        <span class="p">)</span>\n    \n    \n<span class="k">class</span> <span class="nc">SmilesDatasetBatch</span><span class="p">:</span>\n    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>\n        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])]</span>\n        <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])]</span>\n        <span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">b</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])]</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">batch_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">]</span>\n        \n        \n<span class="k">def</span> <span class="nf">collate_smiles_dataset_wrapper</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>\n    <span class="k">return</span> <span class="n">SmilesDatasetBatch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bc5c68b8">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Create the GCN specific lightning module\n     </strong>\n     : in this part we use an object of the\n     <code>\n      SmilesDataset\n     </code>\n     created above to create the\n     <code>\n      SmilesDatasetModule\n     </code>\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=44df652a">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[7]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="k">class</span> <span class="nc">SmilesDatasetModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>\n    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_smiles</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>\n        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">_train_smiles</span> <span class="o">=</span> <span class="n">train_smiles</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">_train_labels</span> <span class="o">=</span> <span class="n">train_labels</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>\n        \n    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">SmilesDataset</span><span class="p">(</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">_train_smiles</span><span class="p">,</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">_train_labels</span><span class="p">,</span>\n        <span class="p">)</span>\n        \n    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>\n        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span>\n            <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">,</span>\n            <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_smiles_dataset_wrapper</span><span class="p">,</span>\n            <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  \n        <span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4115ec6e">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Create the lightning module\n     </strong>\n     : in this part we create the GCN specific lightning module. This class specifies the logic flow for the training step. We also create the required models, optimizers and losses for the training flow.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=61fdd620">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[8]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># prepare the LightningModule</span>\n<span class="k">class</span> <span class="nc">GCNModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>\n    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">n_tasks</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>\n        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span>\n            <span class="s2">"mode"</span><span class="p">,</span>\n            <span class="s2">"n_tasks"</span><span class="p">,</span>\n            <span class="s2">"learning_rate"</span><span class="p">,</span>\n        <span class="p">)</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span> <span class="o">=</span> <span class="n">GCNModel</span><span class="p">(</span>\n            <span class="n">mode</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">mode</span><span class="p">,</span>\n            <span class="n">n_tasks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">n_tasks</span><span class="p">,</span>\n            <span class="n">learning_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>\n        <span class="p">)</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">pt_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span><span class="o">.</span><span class="n">model</span>\n        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span><span class="o">.</span><span class="n">_loss_fn</span>\n        \n    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>\n        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">_create_pytorch_optimizer</span><span class="p">(</span>\n            <span class="bp">self</span><span class="o">.</span><span class="n">pt_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>\n        <span class="p">)</span>\n    \n    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>\n        <span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch_list</span>\n        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span><span class="o">.</span><span class="n">_prepare_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>\n        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pt_model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>\n        \n        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>\n            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">]</span>\n    \n        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span><span class="o">.</span><span class="n">_loss_outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>\n            <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">gcn_model</span><span class="o">.</span><span class="n">_loss_outputs</span><span class="p">]</span>\n    \n        <span class="n">loss_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>\n        \n        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>\n            <span class="s2">"train_loss"</span><span class="p">,</span>\n            <span class="n">loss_outputs</span><span class="p">,</span>\n            <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>\n            <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>\n            <span class="n">reduce_fx</span><span class="o">=</span><span class="s2">"mean"</span><span class="p">,</span>\n            <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>\n        <span class="p">)</span>\n        \n        <span class="k">return</span> <span class="n">loss_outputs</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c3b167c5">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Create the relevant objects\n     </strong>\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=bfff80bd">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[9]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># create module objects</span>\n<span class="n">smiles_datasetmodule</span> <span class="o">=</span> <span class="n">SmilesDatasetModule</span><span class="p">(</span>\n    <span class="n">train_smiles</span><span class="o">=</span><span class="p">[</span><span class="s2">"C1CCC1"</span><span class="p">,</span> <span class="s2">"CCC"</span><span class="p">,</span> <span class="s2">"C1CCC1"</span><span class="p">,</span> <span class="s2">"CCC"</span><span class="p">,</span> <span class="s2">"C1CCC1"</span><span class="p">,</span> <span class="s2">"CCC"</span><span class="p">,</span> <span class="s2">"C1CCC1"</span><span class="p">,</span> <span class="s2">"CCC"</span><span class="p">,</span> <span class="s2">"C1CCC1"</span><span class="p">,</span> <span class="s2">"CCC"</span><span class="p">],</span>\n    <span class="n">train_labels</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>\n    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>\n<span class="p">)</span>\n\n<span class="n">gcnmodule</span> <span class="o">=</span> <span class="n">GCNModule</span><span class="p">(</span>\n    <span class="n">mode</span><span class="o">=</span><span class="s2">"classification"</span><span class="p">,</span>\n    <span class="n">n_tasks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>\n    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>\n<span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ed902521">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <h2>\n     Lightning Trainer\n     <a class="anchor-link" href="#Lightning-Trainer">\n      \xb6\n     </a>\n    </h2>\n    <p>\n     Trainer is the wrapper which builds on top of the\n     <code>\n      LightningDataModule\n     </code>\n     and\n     <code>\n      LightningModule\n     </code>\n     . When constructing the lightning trainer you can also specify the number of epochs, max-steps to run, number of GPUs, number of nodes to be used for trainer. Lightning trainer acts as a wrapper over your distributed training setup and this way you are able to build your models in a way you would build them in a simple way for your local runs.\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=9e002e3a">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[10]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>\n    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>\n<span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">\n     <pre class="overflow-x-scroll">GPU available: False, used: False\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\n</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=870271cd">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n   </div>\n   <div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">\n    <p>\n     <strong>\n      Call the fit function to run model training\n     </strong>\n    </p>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell" id="cell-id=00d35e97">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[11]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span><span class="c1"># train</span>\n<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>\n    <span class="n">model</span><span class="o">=</span><span class="n">gcnmodule</span><span class="p">,</span>\n    <span class="n">datamodule</span><span class="o">=</span><span class="n">smiles_datasetmodule</span><span class="p">,</span>\n<span class="p">)</span>\n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n <div class="jp-Cell-outputWrapper">\n  <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">\n  </div>\n  <div class="jp-OutputArea jp-Cell-outputArea">\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">\n     <pre class="overflow-x-scroll">\n  | Name     | Type | Params\n----------------------------------\n0 | pt_model | GCN  | 29.4 K\n----------------------------------\n29.4 K    Trainable params\n0         Non-trainable params\n29.4 K    Total params\n0.118     Total estimated model params size (MB)\n/Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n/Users/princychahal/mambaforge/envs/keras_try_5/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:428: UserWarning: The number of training samples (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  rank_zero_warn(\n</pre>\n    </div>\n   </div>\n   <div class="jp-OutputArea-child">\n    <div class="jp-OutputPrompt jp-OutputArea-prompt">\n    </div>\n    <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">\n     <pre class="overflow-x-scroll">Training: 0it [00:00, ?it/s]</pre>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=b7537ea2">\n <div class="jp-Cell-inputWrapper">\n  <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">\n  </div>\n  <div class="jp-InputArea jp-Cell-inputArea">\n   <div class="jp-InputPrompt jp-InputArea-prompt">\n    In\xa0[\xa0]:\n   </div>\n   <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">\n    <div class="CodeMirror cm-s-jupyter">\n     <div class="highlight hl-ipython3">\n      <pre class="overflow-x-scroll"><span></span> \n</pre>\n     </div>\n    </div>\n   </div>\n  </div>\n </div>\n</div>\n'},i=n(7294),r=n(7466),c=n.n(r);let o=()=>((0,i.useEffect)(()=>{var s,a;null===(s=document.getElementsByClassName("scroll-nav")[0])||void 0===s||s.remove();let n=document.querySelector(".notebook"),p=document.querySelector(".notebook");p&&n&&c().init(n,{sections:"h1, h2",insertTarget:p,insertLocation:"after"}),null==MathJax||null===(a=MathJax.Hub)||void 0===a||a.Queue(["Typeset",MathJax.Hub])},[]),(0,p.jsx)("div",{className:"overflow-x-scroll",dangerouslySetInnerHTML:{__html:"".concat(t.html," ").concat(l.Z)}}));o.Layout=e.Z;var d=o}},function(s){s.O(0,[2443,9774,2888,179],function(){return s(s.s=2342)}),_N_E=s.O()}]);